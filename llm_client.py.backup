# communication module
import os
import httpx
from typing import List,Dict

class DeepSeekClient:
    """DeepSeek API 客户端"""

    def __init__(self):
        self.api_key = os.getenv("DEEPSEEK_API_KEY")
        if not self.api_key:
            raise ValueError("未找到 DEEPSEEK_API_KEY 环境变量")
        self.base_url = "https://api.deepseek.com/v1/chat/completions"  # 注意：包含 /v1
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

    async def chat(self, messages: List[Dict], max_tokens: int = 2000) -> str:
        """发送消息给Deepseek并获取回复"""
        # 准备请求数据
        data = {
            "model": "deepseek-chat",
            "messages": messages,
            "max_tokens": max_tokens,  # 关键：不再是硬编码的50
            "temperature": 0.7,
            "stream": False
        }

        # 调试日志：查看发送的数据大小
        total_chars = sum(len(msg.get("content", "")) for msg in messages)
        print(f"[LLM Client] 发送 {len(messages)} 条上下文消息，共约 {total_chars} 字符，请求 {max_tokens} tokens")

        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(self.base_url, json=data, headers=self.headers)
                response.raise_for_status()
                result = response.json()

                # 提取回复
                ai_reply = result["choices"][0]["message"]["content"]
                usage = result.get("usage", {})

                # 调试日志：查看返回的完整信息
                print(f"[LLM Client] 收到回复，长度: {len(ai_reply)} 字符")
                print(f"[LLM Client] API消耗: {usage.get('total_tokens', 'N/A')} tokens")
                # 可选：打印前200字符以验证完整性
                # print(f"[LLM Client] 回复预览: {ai_reply[:200]}")

                return ai_reply

        except httpx.TimeoutException:
            print("[LLM Client] 错误: 请求DeepSeek API超时")
            return "请求超时，请稍后重试。"
        except httpx.HTTPStatusError as e:
            print(f"[LLM Client] 错误: API返回 HTTP {e.response.status_code}: {e.response.text[:200]}")
            return f"[API错误] 状态码 {e.response.status_code}"
        except Exception as e:
            print(f"[LLM Client] 未预期错误: {type(e).__name__}: {e}")
            return "处理AI回复时发生未知错误。"

class MockAIClient:
    """模拟AI客户端，用于无API密钥时测试"""
    async def chat(self,messages: List[Dict]) -> str:
        user_msg = messages[-1]["content"].lower()
        if "你好" in user_msg:
            return "你好！我是你的AI桌面机器人，正在开发中。"
        elif "功能" in user_msg:
            return "我目前可以进行对话，未来我会拥有语音、视觉和动作！"
        else:
            return "这是一个模拟回复。要获取真实AI回复，请在'.env' 文件中配置有效的Deepseek API 密钥。"

def get_llm_client():
    """根据配置返回对应的AI客户端"""
    provider = os.getenv("LLM_PROVIDER","deepseek").lower()
    if provider == "deepseek":
        print(f"[LLM Client] 请求的提供者是：'{provider}'")  # 添加这行
        print("[LLM Client] 正在使用 DeepSeek 客户端。")  # 添加这行
        return DeepSeekClient()
    else:
        print("[LLM Client] 正在使用模拟客户端。")  # 添加这行
        return MockAIClient()
